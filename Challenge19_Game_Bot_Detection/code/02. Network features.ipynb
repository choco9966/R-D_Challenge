{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm_notebook # check the progressbar in the python. \n",
    "import glob # check the file name in fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "path = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/dataset/'\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import lit\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "for i in tqdm_notebook(read_file_lst):\n",
    "    # sqlContext.read.csv() : path를 C:Users/..의 형식으로 맞춰줘야함. (초기값이 spark설치된 곳으로 지정되어있음)\n",
    "    df_temp = sqlContext.read.csv(SparkFiles.get(i), header=True, inferSchema= True) # read.csv \n",
    "    \n",
    "    # transformation으로 추가하려면, df = df.withColumn(\"age_square\", col(\"age\")**2)\n",
    "    df_temp = df_temp.withColumn(\"Date\", lit(i[-8:-4])) # column 추가, lit명령어가 value를 추가하는 방법. \n",
    "    \n",
    "    if i == read_file_lst[0]:\n",
    "        df_total = df_temp\n",
    "    else:\n",
    "        df_total = unionAll([df_total, df_temp]) # row-wise 결합\n",
    "        \n",
    "    del df_temp \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.withColumnRenamed(\"actor_account\", \"account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/preprocessing/'\n",
    "df_total.filter(df_total['log_id'] == 126).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"party.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 134).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"friend.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 158).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"dual.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 229).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"mail.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 210).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"trade1.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 219).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"trade2.csv\", index=False)\n",
    "df_total.filter(df_total['log_id'] == 247).select(['account', 'target_account']).toPandas().to_csv(outputpath + \"privateshop.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "path = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/preprocessing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual = pd.read_csv(path + \"dual.csv\")\n",
    "friend = pd.read_csv(path + \"friend.csv\")\n",
    "mail = pd.read_csv(path + \"mail.csv\")\n",
    "party = pd.read_csv(path + \"party.csv\")\n",
    "privateshop = pd.read_csv(path + \"privateshop.csv\")\n",
    "trade1 = pd.read_csv(path + \"trade1.csv\")\n",
    "trade2 = pd.read_csv(path + \"trade2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "path = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/'\n",
    "train = pd.read_csv(path + 'labeled_accounts.csv')\n",
    "test = pd.read_csv(path + 'test_accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_features(train, test, my_graph, name_id):\n",
    "    i = 0\n",
    "    name = [\"degree\", \"between_cc\", \"close_cc\", \"degree_cc\",  \"pagerank\", \"eigen_cc\", \"hub\", \"authorities\"]\n",
    "    degree = nx.degree(my_graph); \n",
    "    between_cc = nx.betweenness_centrality(my_graph); # 이것도 생각보다 오래걸림. \n",
    "    close_cc = nx.closeness_centrality(my_graph);\n",
    "    degree_cc = nx.degree_centrality(my_graph);\n",
    "    eigen_cc = nx.eigenvector_centrality_numpy(my_graph, max_iter=500);\n",
    "    hub, authorities = nx.hits(my_graph);\n",
    "    pagerank = nx.pagerank(my_graph, alpha=0.90); #PageRank applied\n",
    "    \n",
    "    \n",
    "    for fe in [degree, between_cc, close_cc, degree_cc, pagerank, eigen_cc , hub, authorities]:\n",
    "        fe = dict(fe) \n",
    "        fe_df = pd.DataFrame()\n",
    "        fe_df['account'] = list(fe.keys())\n",
    "        fe_df['{}_{}'.format(name_id, name[i])] = list(fe.values())\n",
    "        i = i+1\n",
    "        train = train.merge(fe_df,how='left',on='account')\n",
    "        test = test.merge(fe_df,how='left',on='account')\n",
    "\n",
    "    print(\"Network features maked\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "name_id = [\"dual\", \"friend\"]; num = 0\n",
    "for df in tqdm_notebook([dual, friend, mail]):\n",
    "    network_list = []\n",
    "    for i in tqdm_notebook(np.arange(df.shape[0])):\n",
    "        network_list.append((df.iloc[i]['account'], df.iloc[i]['target_account']))\n",
    "    # Create a networkx graph object\n",
    "\n",
    "    my_graph = nx.Graph() \n",
    "    my_graph.add_edges_from(network_list)\n",
    "    train, test = network_features(train, test, my_graph, name_id[num])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "outputpath = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/features/'\n",
    "train.to_csv(outputpath + \"train_network1.csv\", index=False)\n",
    "test.to_csv(outputpath + \"test_network1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_features(train, test, my_graph, name_id):\n",
    "    i = 0\n",
    "    name = [\"degree\", \"between_cc\", \"close_cc\", \"degree_cc\",  \"pagerank\"]\n",
    "    degree = nx.degree(my_graph); \n",
    "    between_cc = nx.betweenness_centrality(my_graph); # 이것도 생각보다 오래걸림. \n",
    "    close_cc = nx.closeness_centrality(my_graph);\n",
    "    degree_cc = nx.degree_centrality(my_graph);\n",
    "    #eigen_cc = nx.eigenvector_centrality_numpy(my_graph, max_iter=500);\n",
    "    #hub, authorities = nx.hits(my_graph);\n",
    "    pagerank = nx.pagerank(my_graph, alpha=0.90); #PageRank applied\n",
    "    \n",
    "    \n",
    "    for fe in [degree, between_cc, close_cc, degree_cc, pagerank]:\n",
    "        fe = dict(fe) \n",
    "        fe_df = pd.DataFrame()\n",
    "        fe_df['account'] = list(fe.keys())\n",
    "        fe_df['{}_{}'.format(name_id, name[i])] = list(fe.values())\n",
    "        i = i+1\n",
    "        train = train.merge(fe_df,how='left',on='account')\n",
    "        test = test.merge(fe_df,how='left',on='account')\n",
    "\n",
    "    print(\"Network features maked\")\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "path = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/'\n",
    "train = pd.read_csv(path + 'labeled_accounts.csv')\n",
    "test = pd.read_csv(path + 'test_accounts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_id = ['party', 'privateshop', 'trade1', 'trade2']; num = 0\n",
    "for df in tqdm_notebook([party, privateshop, trade1, trade2]):\n",
    "    network_list = []\n",
    "    for i in tqdm_notebook(np.arange(df.shape[0])):\n",
    "        network_list.append((df.iloc[i]['account'], df.iloc[i]['target_account']))\n",
    "    # Create a networkx graph object\n",
    "\n",
    "    my_graph = nx.Graph() \n",
    "    my_graph.add_edges_from(network_list)\n",
    "    train, test = network_features(train, test, my_graph, name_id[num])\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "outputpath = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/features/'\n",
    "train.to_csv(outputpath + \"train_network2.csv\", index=False)\n",
    "test.to_csv(outputpath + \"test_network2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
