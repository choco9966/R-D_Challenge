{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm_notebook # check the progressbar in the python. \n",
    "import glob # check the file name in fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "path = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file_lst = glob.glob(path + '*')\n",
    "read_file_lst[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools \n",
    "\n",
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), dfs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "for i in tqdm_notebook(read_file_lst):\n",
    "    # sqlContext.read.csv() : path를 C:Users/..의 형식으로 맞춰줘야함. (초기값이 spark설치된 곳으로 지정되어있음)\n",
    "    df_temp = sqlContext.read.csv(SparkFiles.get(i), header=True, inferSchema= True) # read.csv \n",
    "    \n",
    "    # transformation으로 추가하려면, df = df.withColumn(\"age_square\", col(\"age\")**2)\n",
    "    df_temp = df_temp.withColumn(\"date\", lit(i[-8:-4])) # column 추가, lit명령어가 value를 추가하는 방법. \n",
    "    \n",
    "    if i == read_file_lst[0]:\n",
    "        df_total = df_temp\n",
    "    else:\n",
    "        df_total = unionAll([df_total, df_temp]) # row-wise 결합\n",
    "        \n",
    "    del df_temp \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "# userItem=df.groupby('userId').agg(f.expr('count(distinct item)').alias('n_item'))\n",
    "# df_total.groupBy(\"log_id\").agg(f.expr('count(distinct item)').alias('log_id'))\n",
    "# df_total.select(\"actor_account\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/'\n",
    "train_label = pd.read_csv(i + \"labeled_accounts.csv\")\n",
    "test_label = pd.read_csv(i + \"test_accounts.csv\")\n",
    "del train_label['class']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print((train_label.count(), len(train_label.columns)))\n",
    "print((test_label.count(), len(test_label.columns)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- train의 size : (356997380, 28)\n",
    "- test의 size : (362572164, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Player information features\n",
    "- Actor (o)\n",
    "- A_Acc (o)\n",
    "- login_day_count \n",
    "- logout_day_count\n",
    "- playtime (o)\n",
    "- playtime_per_day\n",
    "- avg_money (o)\n",
    "- login_count (o)\n",
    "- ip_count (o)\n",
    "- max_level (o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : login_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func # pyspark의 유용한 기능을 사용하는 패키지 : countDistinct 사용가능\n",
    "# 원하는 부분만 출력할때는 df.filter()를 사용. \n",
    "\n",
    "# 아이온데이터에 actor는 다르지만 actor_account가 같은 경우는 있는 것 같음. \n",
    "# 하지만 제출형태가 actor_account를 기준으로 해가지고 groupby를 아래의 변수로 진행했음. \n",
    "df_total = df_total.withColumnRenamed(\"actor_account\", \"account\")\n",
    "\n",
    "df_total_agg = df_total.filter(df_total['log_id'] == 103).select('account').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['account'].agg({'count'}).reset_index().rename(columns={'count':'login_count'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : Day_unique_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 103).select('account','date').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['date'].agg({'nunique'}).reset_index().rename(columns={'nunique':'Day_unique_count'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : ip_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 103).select('account','etc_str1').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['etc_str1'].agg({'nunique'}).reset_index().rename(columns={'nunique':'ip_nunique'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : max_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 103).select('account','etc_num2').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['etc_num2'].agg({'max'}).reset_index().rename(columns={'max':'max_level'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 104).select('account','etc_num7').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['etc_num7'].agg({'mean', 'sum'}).reset_index().rename(columns={'mean':'mean_playtime', 'sum':'sum_playtime'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature name : sum_money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 104).select('account','etc_num1').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')['etc_num1'].agg({'mean', 'sum'}).reset_index().rename(columns={'sum':'sum_money'})\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Feature name : captcha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_agg = df_total.filter(df_total['log_id'] == 116).select('account','etc_num7','etc_num8','etc_num9','etc_num10').toPandas()\n",
    "df_total_agg = df_total_agg.groupby('account')[['etc_num7','etc_num8','etc_num9','etc_num10']].agg({'mean'}).reset_index()\n",
    "df_total_agg.columns = ['account', 'captcha_count_mean', 'captcha_ban_time_mean', 'captcha_prior_time_mean', 'captcha_occur_time_mean']\n",
    "\n",
    "train_label = train_label.merge(df_total_agg, on='account' , how='left')\n",
    "test_label = test_label.merge(df_total_agg, on='account' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User\\Documents\\R&D Challenge2019\n",
    "outputpath = 'C:/Users/User/Documents/R_D Challenge2019/Challenge19_GameBot_Preliminary/features/'\n",
    "train_label.to_csv(outputpath + \"train_player.csv\", index=False)\n",
    "test_label.to_csv(outputpath + \"test_player.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
